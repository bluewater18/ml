{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 401 Assignment 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1 Tuning Hyper-parameters"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "outputs": [],
   "source": [
    "#imports\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import pandas as pd\n",
    "from sklearn import datasets, tree, linear_model\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from IPython.display import display\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from matplotlib.pylab import rcParams\n",
    "\n",
    "rcParams['figure.figsize'] = 50,50"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Several helper functions were created:\n",
    "- get_average \n",
    " - Simply returns the average result of a list\n",
    "- scale_data\n",
    " - A small wrapper function for scaling data appropriately using sklearn's StandardScaler\n",
    "- is_improvement\n",
    " - A function that calculates if the next iteration of the max_depth is a valid improvement. The formula requires that for any 1 increase in the average number of nodes, there should be at least a 1% in accuracy."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "outputs": [],
   "source": [
    "# helper functions\n",
    "\n",
    "def get_average(arr):#returns the average of a python list\n",
    "    s = 0\n",
    "    for a in arr:\n",
    "        s = s + a\n",
    "    avg = s/len(arr)\n",
    "    return avg\n",
    "\n",
    "def scale_data(xtrain, xtest):#scales data using sklearns standard scaler\n",
    "    feature_scaler = StandardScaler()\n",
    "    return feature_scaler.fit_transform(xtrain), feature_scaler.transform(xtest)\n",
    "\n",
    "def is_improvement(prev_accuracy, prev_num_nodes, current_accuracy, current_num_nodes):\n",
    "    if (prev_accuracy is 0) and (prev_num_nodes is 0):\n",
    "        return True\n",
    "    prev_accuracy = prev_accuracy*100\n",
    "    current_accuracy = current_accuracy*100\n",
    "    accuracy_improvement = current_accuracy - prev_accuracy\n",
    "    if accuracy_improvement<=0:\n",
    "        return False\n",
    "    node_delta = current_num_nodes - prev_num_nodes\n",
    "    if accuracy_improvement < node_delta:\n",
    "        return False\n",
    "    return True\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% \n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The k-fold cross validation was contained within a method.<br/>\n",
    "This method takes the training data, as well as some optional parameters relating to the k-fold itself <br/>\n",
    "The method works through max depths of 1 to 15<br/>\n",
    "to achieve this the method runs a for loop through each depth in which it defines a new DecisionTreeClasifier. This DT is then KFolded and each set of test and training data within the k-fold is fitted to the tree, with the accuracy and number of nodes recorded. <br/>\n",
    "For each max depth this is average and used to check if the classifier is a valid improvement.<br>\n",
    "The method finally displays a dataframe and returns the best classifier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "outputs": [],
   "source": [
    "#KFold CV Method\n",
    "def run_KFold_CV(x_train_kf, y_train_kf, n_splits=6, random_state = 0, shuffle = False):\n",
    "    df = pd.DataFrame(columns=['Max_Tree_Depth', 'Average_Accuracy', 'Average_Node_Count'])\n",
    "    depths = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]\n",
    "    prev_avg_accuracy = 0\n",
    "    prev_num_nodes = 0\n",
    "    for depth in depths:\n",
    "        kf_tree = tree.DecisionTreeClassifier(max_depth=depth)\n",
    "        kf = KFold(n_splits=n_splits, random_state=random_state, shuffle=shuffle)\n",
    "        accuracy = []\n",
    "        num_nodes = []\n",
    "        for train_index, test_index in kf.split(x_train_kf):\n",
    "            x_tr, x_te = x_train_kf[train_index], x_train_kf[test_index]\n",
    "            y_tr, y_te = y_train_kf[train_index], y_train_kf[test_index]\n",
    "            kf_tree = kf_tree.fit(x_tr, y_tr)\n",
    "            predictions = kf_tree.predict(x_te)\n",
    "            accuracy.append(kf_tree.score(x_te, y_te))\n",
    "            num_nodes.append(kf_tree.tree_.node_count)\n",
    "            acc_avg = get_average(accuracy)\n",
    "            num_nodes_avg = get_average(num_nodes)\n",
    "        df = df.append({'Max_Tree_Depth':depth, 'Average_Accuracy':acc_avg, 'Average_Node_Count': num_nodes_avg}, ignore_index=True)\n",
    "        if is_improvement(prev_avg_accuracy, prev_num_nodes, acc_avg, num_nodes_avg):\n",
    "            prev_avg_accuracy, prev_num_nodes = acc_avg, num_nodes_avg\n",
    "            best_depth = depth\n",
    "            best_tree = kf_tree\n",
    "    display(df)\n",
    "    print(\"The best classifier was found with depth \", best_depth)\n",
    "    return best_tree\n",
    "\n",
    "def test_best_tree(best_tree, x_te, y_te):\n",
    "    predictions = best_tree.predict(x_te)\n",
    "    accuracy = best_tree.score(x_te, y_te)\n",
    "    print(\"The best classifier achieved an accuracy of \", accuracy, \" on the test data\")\n",
    "    return\n",
    " \n",
    "def train_best_tree(best_tree, x_tr, y_tr, x_te, y_te):\n",
    "    kf_tree = best_tree\n",
    "    \n",
    "    kf_tree.fit(x_tr, y_tr)\n",
    "    \n",
    "    predictions = kf_tree.predict(x_te)\n",
    "    accuracy = kf_tree.score(x_te, y_te)\n",
    "    print(\"The best classifier achieved an accuracy of \", accuracy, \" on the test data when fitted again with all training data\")\n",
    "    return\n",
    "\n",
    "def retrain_best_tree(best_tree, x_tr, y_tr, x_te, y_te):\n",
    "    kf_tree = tree.DecisionTreeClassifier(max_depth=best_tree.max_depth)\n",
    "    \n",
    "    kf_tree.fit(x_tr, y_tr)\n",
    "    \n",
    "    predictions = kf_tree.predict(x_te)\n",
    "    accuracy = kf_tree.score(x_te, y_te)\n",
    "    print(\"The best classifier achieved an accuracy of \", accuracy, \" on the test data when re-fitted with all training data\")\n",
    "    return"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Results\n",
    "Below are the code and results of running the Iris, Breast caner, and Digits datasets respectively"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Iris plant recognition"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "outputs": [
    {
     "data": {
      "text/plain": "    Max_Tree_Depth  Average_Accuracy  Average_Node_Count\n0              1.0          0.611111            3.000000\n1              2.0          0.934096            5.000000\n2              3.0          0.961874            8.333333\n3              4.0          0.942810           11.666667\n4              5.0          0.942810           11.666667\n5              6.0          0.942810           11.333333\n6              7.0          0.942810           11.666667\n7              8.0          0.942810           11.333333\n8              9.0          0.942810           11.333333\n9             10.0          0.942810           11.333333\n10            11.0          0.952070           11.333333\n11            12.0          0.942810           11.666667\n12            13.0          0.942810           11.666667\n13            14.0          0.942810           11.666667\n14            15.0          0.942810           11.333333",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Max_Tree_Depth</th>\n      <th>Average_Accuracy</th>\n      <th>Average_Node_Count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.0</td>\n      <td>0.611111</td>\n      <td>3.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2.0</td>\n      <td>0.934096</td>\n      <td>5.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3.0</td>\n      <td>0.961874</td>\n      <td>8.333333</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4.0</td>\n      <td>0.942810</td>\n      <td>11.666667</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5.0</td>\n      <td>0.942810</td>\n      <td>11.666667</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>6.0</td>\n      <td>0.942810</td>\n      <td>11.333333</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>7.0</td>\n      <td>0.942810</td>\n      <td>11.666667</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>8.0</td>\n      <td>0.942810</td>\n      <td>11.333333</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>9.0</td>\n      <td>0.942810</td>\n      <td>11.333333</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>10.0</td>\n      <td>0.942810</td>\n      <td>11.333333</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>11.0</td>\n      <td>0.952070</td>\n      <td>11.333333</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>12.0</td>\n      <td>0.942810</td>\n      <td>11.666667</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>13.0</td>\n      <td>0.942810</td>\n      <td>11.666667</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>14.0</td>\n      <td>0.942810</td>\n      <td>11.666667</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>15.0</td>\n      <td>0.942810</td>\n      <td>11.333333</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "text": [
      "The best classifier was found with depth  2\nThe best classifier achieved an accuracy of  0.9111111111111111  on the test data\nThe best classifier achieved an accuracy of  0.9111111111111111  on the test data when fitted again with all training data\nThe best classifier achieved an accuracy of  0.9111111111111111  on the test data when re-fitted with all training data\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# Iris plant recognition  \n",
    "iris = datasets.load_iris()\n",
    "iris_X = iris.data\n",
    "iris_Y = iris.target\n",
    "# split into train and test then scale\n",
    "iris_X_train, iris_X_test, iris_y_train, iris_y_test = train_test_split(iris_X, iris_Y, test_size=0.3, random_state=0)\n",
    "iris_X_train, iris_X_test = scale_data(iris_X_train, iris_X_test)\n",
    "# run kflod cv\n",
    "iris_best_tree = run_KFold_CV(iris_X_train, iris_y_train)\n",
    "test_best_tree(iris_best_tree, iris_X_test, iris_y_test)\n",
    "train_best_tree(iris_best_tree, iris_X_train, iris_y_train, iris_X_test, iris_y_test)\n",
    "retrain_best_tree(iris_best_tree, iris_X_train, iris_y_train, iris_X_test, iris_y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Breast cancer diagnosis"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "outputs": [
    {
     "data": {
      "text/plain": "    Max_Tree_Depth  Average_Accuracy  Average_Node_Count\n0              1.0          0.909543            3.000000\n1              2.0          0.907131            7.000000\n2              3.0          0.922207           14.000000\n3              4.0          0.919720           21.000000\n4              5.0          0.927220           26.000000\n5              6.0          0.917157           29.000000\n6              7.0          0.912182           30.000000\n7              8.0          0.907131           30.333333\n8              9.0          0.919607           30.666667\n9             10.0          0.909543           30.666667\n10            11.0          0.907169           30.333333\n11            12.0          0.914594           30.333333\n12            13.0          0.904568           30.000000\n13            14.0          0.914631           30.333333\n14            15.0          0.907056           30.000000",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Max_Tree_Depth</th>\n      <th>Average_Accuracy</th>\n      <th>Average_Node_Count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.0</td>\n      <td>0.909543</td>\n      <td>3.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2.0</td>\n      <td>0.907131</td>\n      <td>7.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3.0</td>\n      <td>0.922207</td>\n      <td>14.000000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4.0</td>\n      <td>0.919720</td>\n      <td>21.000000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5.0</td>\n      <td>0.927220</td>\n      <td>26.000000</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>6.0</td>\n      <td>0.917157</td>\n      <td>29.000000</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>7.0</td>\n      <td>0.912182</td>\n      <td>30.000000</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>8.0</td>\n      <td>0.907131</td>\n      <td>30.333333</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>9.0</td>\n      <td>0.919607</td>\n      <td>30.666667</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>10.0</td>\n      <td>0.909543</td>\n      <td>30.666667</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>11.0</td>\n      <td>0.907169</td>\n      <td>30.333333</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>12.0</td>\n      <td>0.914594</td>\n      <td>30.333333</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>13.0</td>\n      <td>0.904568</td>\n      <td>30.000000</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>14.0</td>\n      <td>0.914631</td>\n      <td>30.333333</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>15.0</td>\n      <td>0.907056</td>\n      <td>30.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "text": [
      "The best classifier was found with depth  1\nThe best classifier achieved an accuracy of  0.8947368421052632  on the test data\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# Breast cancer diagnosis\n",
    "breast_cancer = datasets.load_breast_cancer()\n",
    "breast_cancer_X = breast_cancer.data\n",
    "breast_cancer_Y = breast_cancer.target\n",
    "# split into train and test then scale\n",
    "breast_cancer_X_train, breast_cancer_X_test, breast_cancer_y_train, breast_cancer_y_test = train_test_split(breast_cancer_X, breast_cancer_Y, test_size=0.3, random_state=0)\n",
    "breast_cancer_X_train, breast_cancer_X_test = scale_data(breast_cancer_X_train, breast_cancer_X_test)\n",
    "# run kflod cv\n",
    "breast_cancer_best_tree = run_KFold_CV(breast_cancer_X_train, breast_cancer_y_train)\n",
    "test_best_tree(breast_cancer_best_tree, breast_cancer_X_test, breast_cancer_y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Digit Recognition"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "outputs": [
    {
     "data": {
      "text/plain": "    Max_Tree_Depth  Average_Accuracy  Average_Node_Count\n0              1.0          0.189333            3.000000\n1              2.0          0.316648            7.000000\n2              3.0          0.460652           15.000000\n3              4.0          0.640385           30.333333\n4              5.0          0.707223           53.666667\n5              6.0          0.774053           84.666667\n6              7.0          0.819416          125.333333\n7              8.0          0.828966          166.333333\n8              9.0          0.833736          199.666667\n9             10.0          0.834522          220.000000\n10            11.0          0.835316          231.333333\n11            12.0          0.843282          236.666667\n12            13.0          0.832919          239.333333\n13            14.0          0.834530          240.000000\n14            15.0          0.835327          239.666667",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Max_Tree_Depth</th>\n      <th>Average_Accuracy</th>\n      <th>Average_Node_Count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.0</td>\n      <td>0.189333</td>\n      <td>3.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2.0</td>\n      <td>0.316648</td>\n      <td>7.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3.0</td>\n      <td>0.460652</td>\n      <td>15.000000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4.0</td>\n      <td>0.640385</td>\n      <td>30.333333</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5.0</td>\n      <td>0.707223</td>\n      <td>53.666667</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>6.0</td>\n      <td>0.774053</td>\n      <td>84.666667</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>7.0</td>\n      <td>0.819416</td>\n      <td>125.333333</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>8.0</td>\n      <td>0.828966</td>\n      <td>166.333333</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>9.0</td>\n      <td>0.833736</td>\n      <td>199.666667</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>10.0</td>\n      <td>0.834522</td>\n      <td>220.000000</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>11.0</td>\n      <td>0.835316</td>\n      <td>231.333333</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>12.0</td>\n      <td>0.843282</td>\n      <td>236.666667</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>13.0</td>\n      <td>0.832919</td>\n      <td>239.333333</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>14.0</td>\n      <td>0.834530</td>\n      <td>240.000000</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>15.0</td>\n      <td>0.835327</td>\n      <td>239.666667</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "text": [
      "The best classifier was found with depth  4\nThe best classifier achieved an accuracy of  0.6518518518518519  on the test data\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# Digit recognition\n",
    "# manipulate data into (samples, feature) matrix\n",
    "digits = datasets.load_digits()\n",
    "digits_n_samples = len(digits.images)\n",
    "digits_X = digits.images.reshape((digits_n_samples), -1)\n",
    "digits_y = digits.target\n",
    "# split into train and test then scale\n",
    "digits_X_train, digits_X_test, digits_y_train, digits_y_test = train_test_split(digits_X, digits_y, test_size=0.3, random_state=0)\n",
    "digits_X_train, digits_X_test = scale_data(digits_X_train, digits_X_test)\n",
    "# run kflod cv\n",
    "digits_best_tree = run_KFold_CV(digits_X_train, digits_y_train)\n",
    "test_best_tree(digits_best_tree, digits_X_test, digits_y_test)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2 Decision trees vs linear models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The formula used for the problem was y > x. That is for any data point if the y-value is greater than the x-value it is considered in the positive class. Consequently any data point with  y <= x will be considered in the negative class.<br>\n",
    "To create a data set there are several helper functions below, that randomly generate a dataset of a specified size, consisting of a roughly 50/50 split between the positive and negative class.<br>\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "outputs": [],
   "source": [
    "#Constructing the problem\n",
    "random.seed( 5577993311 )\n",
    "def my_problem(x):\n",
    "    return x,x*(1+random.randint(1,5)/6)\n",
    "    #return x,2*x\n",
    "\n",
    "def get_random_fail(x):\n",
    "    return x, x*(1-random.randint(1,5)/6)\n",
    "    #return x, x*0.5\n",
    "\n",
    "def create_dataset(n=100):\n",
    "    dataset_x = []\n",
    "    dataset_y = []\n",
    "    for i in range(1,n):\n",
    "        if random.randint(0,10) % 2 == 0:\n",
    "            dataset_x.append(my_problem(i))\n",
    "            dataset_y.append(1)\n",
    "        else:\n",
    "            dataset_x.append(get_random_fail(i))\n",
    "            dataset_y.append(0)\n",
    "    return dataset_x, dataset_y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The testing the linear and decision tree classifications was done at different dataset sizes and max depths (for the\n",
    "decision tree). The dataset sizes varied from 20 to "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "dataset of size:  50  --  [((1, 0.33333333333333337), 0), ((2, 1.3333333333333335), 0), ((3, 0.4999999999999999), 0), ((4, 1.3333333333333335), 0), ((5, 3.333333333333334), 0), ((6, 4.0), 0), ((7, 10.5), 1), ((8, 10.666666666666666), 1), ((9, 12.0), 1), ((10, 18.333333333333336), 1), ((11, 7.333333333333334), 0), ((12, 22.0), 1), ((13, 4.333333333333334), 0), ((14, 21.0), 1), ((15, 2.4999999999999996), 0), ((16, 5.333333333333334), 0), ((17, 28.333333333333332), 1), ((18, 29.999999999999996), 1), ((19, 31.666666666666664), 1), ((20, 3.3333333333333326), 0), ((21, 24.5), 1), ((22, 33.0), 1), ((23, 26.833333333333336), 1), ((24, 16.0), 0), ((25, 37.5), 1), ((26, 30.333333333333336), 1), ((27, 13.5), 0), ((28, 37.33333333333333), 1), ((29, 33.833333333333336), 1), ((30, 4.999999999999999), 0), ((31, 36.16666666666667), 1), ((32, 26.666666666666668), 0), ((33, 44.0), 1), ((34, 11.333333333333334), 0), ((35, 46.666666666666664), 1), ((36, 12.000000000000002), 0), ((37, 61.666666666666664), 1), ((38, 57.0), 1), ((39, 52.0), 1), ((40, 20.0), 0), ((41, 20.5), 0), ((42, 70.0), 1), ((43, 78.83333333333334), 1), ((44, 14.666666666666668), 0), ((45, 37.5), 0), ((46, 23.0), 0), ((47, 86.16666666666667), 1), ((48, 40.0), 0), ((49, 57.16666666666667), 1)]\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "   Dataset Size  Score\n0          50.0    1.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Dataset Size</th>\n      <th>Score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>50.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "   Dataset Size  Max Depth     Score\n0          50.0        1.0  0.800000\n1          50.0        3.0  0.866667\n2          50.0        5.0  0.866667\n3          50.0        7.0  0.866667\n4          50.0        9.0  0.866667\n5          50.0       11.0  0.866667\n6          50.0       13.0  0.866667",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Dataset Size</th>\n      <th>Max Depth</th>\n      <th>Score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>50.0</td>\n      <td>1.0</td>\n      <td>0.800000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>50.0</td>\n      <td>3.0</td>\n      <td>0.866667</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>50.0</td>\n      <td>5.0</td>\n      <td>0.866667</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>50.0</td>\n      <td>7.0</td>\n      <td>0.866667</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>50.0</td>\n      <td>9.0</td>\n      <td>0.866667</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>50.0</td>\n      <td>11.0</td>\n      <td>0.866667</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>50.0</td>\n      <td>13.0</td>\n      <td>0.866667</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ldf = pd.DataFrame(columns=['Dataset Size', 'Score'])\n",
    "tdf = pd.DataFrame(columns=['Dataset Size', 'Max Depth', 'Score'])\n",
    "for k in range(50, 51, 100):\n",
    "    x,y = create_dataset(k)\n",
    "    print('dataset of size: ',k, ' -- ',list(zip(x,y)))\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=0)\n",
    "    linear = linear_model.LogisticRegression(random_state=0, solver='lbfgs')\n",
    "    linear.fit(x_train, y_train)\n",
    "    linear_predict = linear.predict(x_test)\n",
    "    linear_predict = linear_predict.tolist()\n",
    "    #l_accuracy = accuracy_score(y_test, linear_predict)\n",
    "    l_score = linear.score(x_test, y_test)\n",
    "    ldf = ldf.append({'Dataset Size':k, 'Score':l_score}, ignore_index=True)\n",
    "    for l in range(1,15,2):\n",
    "        d_tree = tree.DecisionTreeClassifier(max_depth=l, random_state=0)\n",
    "        d_tree = d_tree.fit(x_train, y_train)\n",
    "        d_tree_predict = d_tree.predict(x_test)\n",
    "        #d_tree_accuracy = accuracy_score(y_test, d_tree_predict)\n",
    "        score = d_tree.score(x_test, y_test)\n",
    "        tdf = tdf.append({'Dataset Size':k, 'Max Depth':l,'Score':score}, ignore_index=True)\n",
    "\n",
    "display(ldf)\n",
    "display(tdf)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "DecisionTreeClassifier with max_depth = 8 and score =  0.8333333333333334\n"
     ],
     "output_type": "stream"
    },
    {
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-224-873520593de3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0my_min\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ma\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ma\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m xx, yy = np.meshgrid(np.arange(x_min, x_max, plot_step),\n\u001b[1;32m---> 16\u001b[1;33m np.arange(y_min, y_max, plot_step))\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtight_layout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh_pad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw_pad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mZ\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0md_tree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mxx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mmeshgrid\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32mc:\\users\\morgan\\pycharmprojects\\untitled\\venv\\lib\\site-packages\\numpy\\lib\\function_base.py\u001b[0m in \u001b[0;36mmeshgrid\u001b[1;34m(*xi, **kwargs)\u001b[0m\n\u001b[0;32m   4214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4215\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcopy_\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4216\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4218\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\morgan\\pycharmprojects\\untitled\\venv\\lib\\site-packages\\numpy\\lib\\function_base.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   4214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4215\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcopy_\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4216\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4218\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate array with shape (8217, 4900) and data type float64"
     ],
     "ename": "MemoryError",
     "evalue": "Unable to allocate array with shape (8217, 4900) and data type float64",
     "output_type": "error"
    }
   ],
   "source": [
    "x, y = create_dataset(100)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=0)\n",
    "d_tree = tree.DecisionTreeClassifier(max_depth=8)\n",
    "d_tree = d_tree.fit(x_train, y_train)\n",
    "d_tree_predict = d_tree.predict(x_test)\n",
    "#d_tree_accuracy = accuracy_score(y_test, d_tree_predict)\n",
    "score = d_tree.score(x_test, y_test)\n",
    "print('DecisionTreeClassifier with max_depth = 8 and score = ', score)\n",
    "#PLOT THE DTREE BOUNDARY\n",
    "plot_step = 0.02\n",
    "X=x\n",
    "Y=y\n",
    "x_min, x_max = min([a for a,_ in x]), max([a for a,_ in x])\n",
    "y_min, y_max = min([a for _,a in x]), max([a for _,a in x])\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, plot_step),\n",
    "np.arange(y_min, y_max, plot_step))\n",
    "plt.tight_layout(h_pad=0.5, w_pad=0.5, pad=2.5)\n",
    "Z = d_tree.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "cs = plt.contourf(xx, yy, Z, cmap=plt.cm.RdYlBu)\n",
    "\n",
    "#Plot points\n",
    "i = range(1,100,1)\n",
    "plt.scatter([a for a,_ in x], [a for _,a in x], color='black', linewidths=10 )\n",
    "plt.plot(i,i, color='yellow')\n",
    "plt.xticks()\n",
    "plt.yticks()\n",
    "plt.figure()\n",
    "plot_tree(d_tree, filled=True, fontsize=30)\n",
    "plt.show()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Implications for R<sup>d</sup>\n",
    "The situation above details a problem in R<sup>2</sup>, however when looking at R<sup>d</sup> when d (the dimension of \n",
    "the problem) increases it becomes more complex for both classifiers. However a linear logistic regression will still be\n",
    "able to easily classify the data using only a linear increase in complexity. However a decision tree will increase in\n",
    "complexity exponentially, this is because the tree makes decisions based on one dimension at a time, thus for each\n",
    "decision made in a dimension there needs to be decisions for other dimensions, consequently as the complexity of the\n",
    "tree increases so to does the possibility of over-fitting"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3 Regression on mixed data types\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#load csv file\n",
    "csv_pf = pd.read_csv('assignment1-2019-data.csv')\n",
    "# display(csv_pf)\n",
    "\n",
    "# applying one hot encoding\n",
    "csv_pf_dummy = pd.get_dummies(csv_pf.X4)\n",
    "csv_pf = csv_pf.join(csv_pf_dummy)\n",
    "# display(csv_pf)\n",
    "\n",
    "# format data\n",
    "subset_X = csv_pf[['X1', 'X2', 'X3','A', 'B', 'C']]\n",
    "csv_X = [tuple(x) for x in subset_X.values]\n",
    "\n",
    "subset_Y = csv_pf[['Y']]\n",
    "csv_Y = [tuple(x) for x in subset_Y.values]\n",
    "# \n",
    "csv_linear = linear_model.LinearRegression()\n",
    "csv_linear = csv_linear.fit(csv_X, csv_Y)\n",
    "print('intercept: ', csv_linear.intercept_[0])\n",
    "print('coefficients: ', list(csv_linear.coef_[0]))\n",
    "print('rounded coefficients: ', list(round(x) for x in csv_linear.coef_[0]))\n",
    "\n",
    "csv_pred = csv_linear.predict(csv_X)\n",
    "print('mean squared error: ', mean_squared_error(csv_Y, csv_pred))\n",
    "print('R-squared: ', r2_score(csv_Y, csv_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Case based definition of functions\n",
    "The linear model identified functions on the"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### assigning a predicted value\n",
    "Upon seeing a new value "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}